# NetFlow to OpenTelemetry Traces - Task Tracker
# This file tracks implementation progress and can be used to resume work

## Project Setup
[x] Create pyproject.toml with Python 3.14 and dependencies
[x] Create project directory structure (src/netflow2traces/)

## Core Implementation
[x] Implement config.py (environment variable configuration)
[x] Implement tracer.py (OpenTelemetry setup)
[x] Implement utils.py (protocol mappings and helpers)
[x] Implement collector.py (UDP listener with Scapy)
[x] Implement __main__.py (main entry point)
[x] Create __init__.py files

## Docker & Deployment
[x] Create Dockerfile with multi-stage build
[x] Create docker-compose.yml with Tempo and Mimir
[x] Create tempo.yaml configuration
[x] Create mimir.yaml configuration
[x] Create .dockerignore file

## Documentation & Configuration
[x] Create .env.example with configuration options
[x] Create README.md with documentation

## Testing & Validation
[x] Test application with sample NetFlow data
[x] Verify application starts and listens correctly
[x] Create test script (test_netflow_sender.py) for manual testing

## Next Steps (for user)
[ ] Start services: docker-compose up -d
[ ] Run application: source .venv/bin/activate && python -m netflow2traces
[ ] Send test data: python test_netflow_sender.py
[ ] Query traces via Tempo API at http://localhost:3200/api/search
[ ] View metrics in Mimir at http://localhost:9009
[ ] Test with different NetFlow versions (v5, v9, IPFIX)
[ ] Configure real NetFlow exporters to send to port 2055
[ ] Optional: Add Grafana to visualize traces and metrics

## Potential Enhancements
[ ] Fix collector shutdown so the listen loop exits cleanly after `stop()` closes the socket; currently `self.sock` becomes `None` and the loop raises repeated attribute errors (src/netflow2traces/collector.py:86,270-276)
[ ] Integrate `NetflowSession` template caching in `_parse_netflow` so v9/IPFIX templates persist across packets instead of being re-parsed ad hoc (src/netflow2traces/collector.py:42-165)
[ ] Add a dedicated `netflow.parse_packet` span to capture parsing latency and align runtime telemetry with the README trace diagram (src/netflow2traces/collector.py:140-167)
[ ] Expose ingestion health metrics (packets, flows, errors per second) via OpenTelemetry metrics or Prometheus so operators can alert on drop conditions (collector/tracer modules)
[ ] Allow configuring OTLP auth headers/TLS options for exporters that require tokens (e.g., Grafana Cloud) instead of only supporting plain endpoint URLs (src/netflow2traces/tracer.py:70-109)
[ ] Provide configurable flow sampling/filtering to tame cardinality before spans are created (src/netflow2traces/config.py:22-74, src/netflow2traces/collector.py:246-268)

## Notes
- Using Scapy for NetFlow parsing (automatic template handling)
- One trace per export packet, flow records as child spans
- Configurable OTLP protocol (gRPC or HTTP)
- Python 3.14 with uv package management
- Docker setup uses Grafana Tempo for traces and Mimir for metrics
- Tempo metrics generator sends span metrics to Mimir
