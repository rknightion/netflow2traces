# NetFlow to OpenTelemetry Traces - Task Tracker
# This file tracks implementation progress and can be used to resume work

## Project Setup
[x] Create pyproject.toml with Python 3.14 and dependencies
[x] Create project directory structure (src/netflow2traces/)

## Core Implementation
[x] Implement config.py (environment variable configuration)
[x] Implement tracer.py (OpenTelemetry setup)
[x] Implement utils.py (protocol mappings and helpers)
[x] Implement collector.py (UDP listener with Scapy)
[x] Implement __main__.py (main entry point)
[x] Create __init__.py files

## Docker & Deployment
[x] Create Dockerfile with multi-stage build
[x] Create docker-compose.yml with Tempo and Prometheus
[x] Create tempo.yaml configuration
[x] Create prometheus.yaml configuration
[x] Create .dockerignore file

## Documentation & Configuration
[x] Create .env.example with configuration options
[x] Create README.md with documentation

## Testing & Validation
[x] Test application with sample NetFlow data
[x] Verify application starts and listens correctly
[x] Create test script (test_netflow_sender.py) for manual testing

## Potential Enhancements
[x] Fix collector shutdown so the listen loop exits cleanly after `stop()` closes the socket; currently `self.sock` becomes `None` and the loop raises repeated attribute errors (src/netflow2traces/collector.py:86,270-276)
[x] Integrate `NetflowSession` template caching in `_parse_netflow` so v9/IPFIX templates persist across packets instead of being re-parsed ad hoc (src/netflow2traces/collector.py:42-165)
[x] Add a dedicated `netflow.parse_packet` span to capture parsing latency and align runtime telemetry with the README trace diagram (src/netflow2traces/collector.py:140-167)
[ ] Expose ingestion health metrics (packets, flows, errors per second) via OpenTelemetry metrics or Prometheus so operators can alert on drop conditions (collector/tracer modules)
[ ] Allow configuring OTLP auth headers/TLS options for exporters that require tokens (e.g., Grafana Cloud) instead of only supporting plain endpoint URLs (src/netflow2traces/tracer.py:70-109)
[ ] Provide configurable flow sampling/filtering to tame cardinality before spans are created (src/netflow2traces/config.py:22-74, src/netflow2traces/collector.py:246-268)

## Notes
- Using Scapy for NetFlow parsing (automatic template handling)
- One trace per export packet, flow records as child spans
- Configurable OTLP protocol (gRPC or HTTP)
- Python 3.14 with uv package management
- Docker setup uses Grafana Tempo for traces and Prometheus for metrics
- Tempo metrics generator sends span metrics to Prometheus via remote write
